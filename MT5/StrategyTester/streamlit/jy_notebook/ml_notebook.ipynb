{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: chardet in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (4.55.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Trading Data Analysis and Regression\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Trading Data Analysis and Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "class TradingFeatureExtractor:\n",
    "    \"\"\"Extract and process features from trading data.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_factor_string(factor_str: str) -> Dict[str, float]:\n",
    "        \"\"\"Parse string of format 'key1=value1|key2=value2' into a dictionary.\"\"\"\n",
    "        if pd.isna(factor_str) or factor_str == '':\n",
    "            return {}\n",
    "        \n",
    "        result = {}\n",
    "        pairs = factor_str.split('|')\n",
    "        \n",
    "        for pair in pairs:\n",
    "            if '=' not in pair:\n",
    "                continue\n",
    "            key, value = pair.split('=')\n",
    "            try:\n",
    "                result[key.strip()] = float(value.strip())\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def extract_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Extract features from the complex columns.\"\"\"\n",
    "        # Create copy of input DataFrame\n",
    "        processed_df = df.copy()\n",
    "        \n",
    "        # Convert Time to datetime\n",
    "        processed_df['Time'] = pd.to_datetime(processed_df['Time'])\n",
    "        \n",
    "        # Add basic trading features\n",
    "        processed_df['TradeDirection'] = processed_df['Action'].map({\n",
    "            'BUY': 1, 'SELL': -1, 'CLOSE': 0\n",
    "        })\n",
    "        \n",
    "        # Calculate trade duration\n",
    "        processed_df['TradeDuration'] = (\n",
    "            processed_df.groupby('Ticket')['Time']\n",
    "            .diff()\n",
    "            .dt.total_seconds()\n",
    "        )\n",
    "        \n",
    "        # Process factor columns\n",
    "        factor_columns = ['factors', 'score', 'efactors', 'exitScore']\n",
    "        \n",
    "        for col in factor_columns:\n",
    "            if col not in processed_df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Parse factor strings\n",
    "            parsed_dicts = processed_df[col].apply(self.parse_factor_string)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            features_df = pd.DataFrame.from_records(parsed_dicts.tolist())\n",
    "            \n",
    "            if not features_df.empty:\n",
    "                # Add column prefix to avoid name conflicts\n",
    "                features_df.columns = [f\"{col}_{c}\" for c in features_df.columns]\n",
    "                \n",
    "                # Join with main DataFrame\n",
    "                processed_df = pd.concat(\n",
    "                    [processed_df.drop(col, axis=1), features_df],\n",
    "                    axis=1\n",
    "                )\n",
    "        \n",
    "        return processed_df\n",
    "\n",
    "class TradingAnalysis:\n",
    "    \"\"\"Analysis of trading data with ML models.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.feature_extractor = TradingFeatureExtractor()\n",
    "        self.processed_df = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def preprocess_data(self, target_col: str = 'CurrentProfit'):\n",
    "        \"\"\"Preprocess the data and prepare for modeling.\"\"\"\n",
    "        # Extract features\n",
    "        self.processed_df = self.feature_extractor.extract_features(self.df)\n",
    "        \n",
    "        # Select numeric columns only\n",
    "        numeric_cols = self.processed_df.select_dtypes(\n",
    "            include=[np.number]\n",
    "        ).columns\n",
    "        \n",
    "        # Remove target and any unwanted columns\n",
    "        feature_cols = [\n",
    "            col for col in numeric_cols \n",
    "            if col not in [target_col, 'Ticket', 'TradeDuration']\n",
    "        ]\n",
    "        \n",
    "        self.X = self.processed_df[feature_cols]\n",
    "        self.y = self.processed_df[target_col]\n",
    "        \n",
    "        # Handle missing values\n",
    "        self.X = self.X.fillna(0)\n",
    "        \n",
    "        return self.X, self.y\n",
    "    \n",
    "    def train_models(self, test_size: float = 0.2):\n",
    "        \"\"\"Train multiple regression models.\"\"\"\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Initialize models\n",
    "        models = {\n",
    "            'linear': LinearRegression(),\n",
    "            'ridge': Ridge(alpha=1.0),\n",
    "            'lasso': Lasso(alpha=1.0)\n",
    "        }\n",
    "        \n",
    "        # Train and evaluate each model\n",
    "        for name, model in models.items():\n",
    "            # Train\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Store results\n",
    "            self.results[name] = {\n",
    "                'model': model,\n",
    "                'predictions': y_pred,\n",
    "                'true_values': y_test,\n",
    "                'r2_score': r2_score(y_test, y_pred),\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "                'feature_importance': pd.DataFrame({\n",
    "                    'feature': self.X.columns,\n",
    "                    'importance': np.abs(model.coef_)\n",
    "                }).sort_values('importance', ascending=False)\n",
    "            }\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"Plot analysis results.\"\"\"\n",
    "        # Set up the plotting area\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Regression Analysis Results', fontsize=16)\n",
    "        \n",
    "        # Plot actual vs predicted for each model\n",
    "        for i, (name, results) in enumerate(self.results.items()):\n",
    "            ax = axes[i // 2, i % 2]\n",
    "            ax.scatter(\n",
    "                results['true_values'],\n",
    "                results['predictions'],\n",
    "                alpha=0.5\n",
    "            )\n",
    "            ax.plot(\n",
    "                [min(results['true_values']), max(results['true_values'])],\n",
    "                [min(results['true_values']), max(results['true_values'])],\n",
    "                'r--'\n",
    "            )\n",
    "            ax.set_title(f'{name.capitalize()} Regression\\nR² = {results[\"r2_score\"]:.3f}')\n",
    "            ax.set_xlabel('Actual Values')\n",
    "            ax.set_ylabel('Predicted Values')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for name, results in self.results.items():\n",
    "            top_features = results['feature_importance'].head(10)\n",
    "            plt.bar(\n",
    "                range(len(top_features)),\n",
    "                top_features['importance'],\n",
    "                alpha=0.3,\n",
    "                label=name\n",
    "            )\n",
    "        \n",
    "        plt.title('Top 10 Feature Importance by Model')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.xticks(\n",
    "            range(len(top_features)),\n",
    "            top_features['feature'],\n",
    "            rotation=45,\n",
    "            ha='right'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage in Jupyter notebook:\n",
    "'''\n",
    "# Load the data\n",
    "df = pd.read_csv('your_trading_data.csv')\n",
    "\n",
    "# Initialize analysis\n",
    "analysis = TradingAnalysis(df)\n",
    "\n",
    "# Preprocess data\n",
    "X, y = analysis.preprocess_data(target_col='CurrentProfit')\n",
    "\n",
    "# Train models\n",
    "results = analysis.train_models()\n",
    "\n",
    "# Plot results\n",
    "analysis.plot_results()\n",
    "\n",
    "# Access detailed results\n",
    "for model_name, model_results in results.items():\n",
    "    print(f\"\\n{model_name.capitalize()} Regression Results:\")\n",
    "    print(f\"R² Score: {model_results['r2_score']:.3f}\")\n",
    "    print(f\"RMSE: {model_results['rmse']:.3f}\")\n",
    "    print(\"\\nTop 5 Important Features:\")\n",
    "    print(model_results['feature_importance'].head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv('path_to_your_csv')\n",
    "\n",
    "# Initialize the analysis\n",
    "analysis = TradingAnalysis(df)\n",
    "\n",
    "# Preprocess the data\n",
    "X, y = analysis.preprocess_data()\n",
    "\n",
    "# Train the models\n",
    "results = analysis.train_models()\n",
    "\n",
    "# Visualize the results\n",
    "analysis.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
