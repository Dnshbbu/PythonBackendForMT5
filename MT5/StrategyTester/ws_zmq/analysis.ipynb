{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "Load the CSV file, handle datetime conversion, parse the factors and scores columns into separate features, and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\stduser\\.pyenv\\pyenv-win\\versions\\3.11.3\\lib\\site-packages (2.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\StdUser\\Desktop\\MyProjects\\Backtesting\\logs\\SYM_10030436_transactions.csv\"\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "# Convert 'Time' column to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%Y.%m.%d %H:%M')\n",
    "\n",
    "# Parse 'factors' and 'score' columns into separate features\n",
    "factors_df = df['factors'].str.split('|', expand=True).apply(lambda x: x.str.split('=', expand=True).set_index(0).T, axis=1)\n",
    "factors_df.columns = factors_df.columns.droplevel(0)\n",
    "factors_df = factors_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "score_df = df['score'].str.split('|', expand=True).apply(lambda x: x.str.split('=', expand=True).set_index(0).T, axis=1)\n",
    "score_df.columns = score_df.columns.droplevel(0)\n",
    "score_df = score_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Concatenate the parsed factors and scores back to the original dataframe\n",
    "df = pd.concat([df, factors_df, score_df], axis=1)\n",
    "\n",
    "# Drop the original 'factors' and 'score' columns\n",
    "df.drop(columns=['factors', 'score'], inplace=True)\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Extract numerical values from the factors string, create new features from the trading metrics, and prepare the target variable (profit/performance metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Extract numerical values from 'efactors' and 'exitScore' columns\n",
    "efactors_df = df['efactors'].str.split('|', expand=True).apply(lambda x: x.str.split('=', expand=True).set_index(0).T, axis=1)\n",
    "efactors_df.columns = efactors_df.columns.droplevel(0)\n",
    "efactors_df = efactors_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "exit_score_df = df['exitScore'].str.split('|', expand=True).apply(lambda x: x.str.split('=', expand=True).set_index(0).T, axis=1)\n",
    "exit_score_df.columns = exit_score_df.columns.droplevel(0)\n",
    "exit_score_df = exit_score_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Concatenate the parsed efactors and exit scores back to the original dataframe\n",
    "df = pd.concat([df, efactors_df, exit_score_df], axis=1)\n",
    "\n",
    "# Drop the original 'efactors' and 'exitScore' columns\n",
    "df.drop(columns=['efactors', 'exitScore'], inplace=True)\n",
    "\n",
    "# Create new features from trading metrics\n",
    "df['PriceChange'] = df['Price'] - df['Price'].shift(1)\n",
    "df['VolumeChange'] = df['Volume'] - df['Volume'].shift(1)\n",
    "df['ProfitChange'] = df['CurrentProfit'] - df['CurrentProfit'].shift(1)\n",
    "\n",
    "# Prepare the target variable (CurrentProfit)\n",
    "target = df['CurrentProfit']\n",
    "\n",
    "# Display the first few rows of the dataframe with new features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "Calculate and visualize correlations between different factors and trading performance using heatmaps and correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Display the top correlations with the target variable (CurrentProfit)\n",
    "target_correlations = correlation_matrix['CurrentProfit'].sort_values(ascending=False)\n",
    "print(\"Top correlations with CurrentProfit:\")\n",
    "print(target_correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance with Random Forest\n",
    "Implement Random Forest to identify the most important factors affecting trading decisions and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y)\n",
    "X = df.drop(columns=['CurrentProfit', 'Time', 'Ticket', 'Action', 'Symbol', 'CloseReason'])\n",
    "y = df['CurrentProfit']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "Train multiple ML models (Random Forest, XGBoost) to predict trading success based on factors, evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with XGBoost\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for XGBoost\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
    "\n",
    "# Calculate the R-squared score for XGBoost\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost R-squared Score: {r2_xgb}\")\n",
    "\n",
    "# Compare model performance\n",
    "print(f\"Random Forest Mean Squared Error: {mse}\")\n",
    "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
    "\n",
    "print(f\"Random Forest R-squared Score: {rf.score(X_test, y_test)}\")\n",
    "print(f\"XGBoost R-squared Score: {r2_xgb}\")\n",
    "\n",
    "# Plotting feature importances for XGBoost\n",
    "xgb_importances = xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame for XGBoost feature importances\n",
    "xgb_importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': xgb_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "xgb_importances_df = xgb_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the XGBoost feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=xgb_importances_df)\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Impact Visualization\n",
    "Create visualizations showing the impact of key factors on trading performance using plots and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor Impact Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize the impact of top factors on trading performance\n",
    "top_factors = feature_importances_df.head(10)['Feature']\n",
    "\n",
    "# Plot the impact of top factors on CurrentProfit\n",
    "plt.figure(figsize=(14, 10))\n",
    "for factor in top_factors:\n",
    "    sns.scatterplot(x=df[factor], y=df['CurrentProfit'], label=factor)\n",
    "\n",
    "plt.title('Impact of Top Factors on CurrentProfit')\n",
    "plt.xlabel('Factor Value')\n",
    "plt.ylabel('CurrentProfit')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of CurrentProfit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['CurrentProfit'], kde=True, bins=30)\n",
    "plt.title('Distribution of CurrentProfit')\n",
    "plt.xlabel('CurrentProfit')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between PriceChange and CurrentProfit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=df['PriceChange'], y=df['CurrentProfit'])\n",
    "plt.title('PriceChange vs CurrentProfit')\n",
    "plt.xlabel('PriceChange')\n",
    "plt.ylabel('CurrentProfit')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between VolumeChange and CurrentProfit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=df['VolumeChange'], y=df['CurrentProfit'])\n",
    "plt.title('VolumeChange vs CurrentProfit')\n",
    "plt.xlabel('VolumeChange')\n",
    "plt.ylabel('CurrentProfit')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between ProfitChange and CurrentProfit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=df['ProfitChange'], y=df['CurrentProfit'])\n",
    "plt.title('ProfitChange vs CurrentProfit')\n",
    "plt.xlabel('ProfitChange')\n",
    "plt.ylabel('CurrentProfit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Analysis\n",
    "Use the model insights to suggest optimal factor thresholds and strategy improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Analysis\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the objective function to minimize (negative profit)\n",
    "def objective_function(params, df, top_factors):\n",
    "    df_copy = df.copy()\n",
    "    for i, factor in enumerate(top_factors):\n",
    "        df_copy[factor] = df_copy[factor] * params[i]\n",
    "    X = df_copy[top_factors]\n",
    "    y = df_copy['CurrentProfit']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Get the top factors from the feature importances\n",
    "top_factors = feature_importances_df.head(10)['Feature'].values\n",
    "\n",
    "# Initial parameters (all ones)\n",
    "initial_params = np.ones(len(top_factors))\n",
    "\n",
    "# Perform the optimization\n",
    "result = minimize(objective_function, initial_params, args=(df, top_factors), method='Nelder-Mead')\n",
    "\n",
    "# Get the optimized parameters\n",
    "optimized_params = result.x\n",
    "\n",
    "# Display the optimized parameters\n",
    "print(\"Optimized Parameters:\")\n",
    "for factor, param in zip(top_factors, optimized_params):\n",
    "    print(f\"{factor}: {param}\")\n",
    "\n",
    "# Apply the optimized parameters to the dataframe\n",
    "for i, factor in enumerate(top_factors):\n",
    "    df[factor] = df[factor] * optimized_params[i]\n",
    "\n",
    "# Re-evaluate the model with optimized factors\n",
    "X_optimized = df[top_factors]\n",
    "y = df['CurrentProfit']\n",
    "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_optimized, y, test_size=0.2, random_state=42)\n",
    "model_opt = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_opt.fit(X_train_opt, y_train_opt)\n",
    "y_pred_opt = model_opt.predict(X_test_opt)\n",
    "mse_opt = mean_squared_error(y_test_opt, y_pred_opt)\n",
    "r2_opt = r2_score(y_test_opt, y_pred_opt)\n",
    "\n",
    "# Display the optimized model performance\n",
    "print(f\"Optimized Mean Squared Error: {mse_opt}\")\n",
    "print(f\"Optimized R-squared Score: {r2_opt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
